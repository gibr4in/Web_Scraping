{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5206014f-3fa9-4b61-ac6f-6231c64196b2",
   "metadata": {},
   "source": [
    "# **Web Scraping with BeautifulSoup**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcdfd6c-9e38-4fef-9eba-4dc81dfb3d0e",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115bee5e-b722-4847-9d8e-673b08a3cbf1",
   "metadata": {},
   "source": [
    "If you have visited websites like data.gov or kaggle.com (and if you are reading this portfolio project, chances are that you have!), you might have noticed that most of the times you need more than one data file to get the information you are looking for"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47155d12-8e24-4fd9-a01d-3fc820109f44",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2915ff-847c-42ab-88bf-612d0ceb1fd6",
   "metadata": {},
   "source": [
    "In this project, a function was created to retrieve the .cvs and .xlsx urls (and files) available on a table containing urls to the given data files. The url to the Livestock and Meat Domestic Data page from the Economic Research Service website was used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6050367-fb60-458a-8af1-7cca519ce915",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079b0ed6-b482-4402-b4a8-b95b2acab970",
   "metadata": {},
   "source": [
    "For this project, the following libraries were used:\n",
    "* urllib.- A python package that provides several modules for working with URLs, such as opening, reading, parsing, and handling errors.\n",
    "* requests.- A python library that simplifies working with HTTP requests. It allows you to send and receive data from web services with different methods, such as GET, POST, PUT, and DELETE\n",
    "* BeautifulSoup.- A Python library that helps you extract data from HTML and XML files.\n",
    "* Pandas.- A Python library that allows you to create manipulable data structures (DataFrames), among it's functionalities are: reading and saving csv an xlsx files.\n",
    "* io.- A Python Library that allows you to manage the file-related input and output operations of python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "778fb9e8-9bed-4566-8cbd-7fcc68c27e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c357287-0250-4f0e-be9c-832f590470e7",
   "metadata": {},
   "source": [
    "## Setting our URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df2e3308-1a10-4b28-9a74-b827ffd319ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = r\"https://www.ers.usda.gov/data-products/livestock-meat-domestic-data/\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57815704-62cf-409c-98a1-f46e2c87fba2",
   "metadata": {},
   "source": [
    "## Creating our function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72c500f0-82d5-43c9-b439-a8db3f17d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadables(url):\n",
    "    '''\n",
    "    This function creates a beautifulsoup that parses the url provided, then gets the table on the url by finding its class attribute and gets the number of\n",
    "    urls that have \"csv\" and \"xlsx\" on them. \n",
    "    Finally, it prints the total number of urls present on the table, and the number of \"csv\" and \"xlsx\" present respectively.\n",
    "    \n",
    "    param url: the url of a page that contains a table with .xlsx and .csv files\n",
    "    \n",
    "    return list of url strings that download xlsx, list of url that contains csv\n",
    "    '''\n",
    "    \n",
    "    def get_parsed_html(url):\n",
    "        '''\n",
    "        param url: string of a url to be scraped\n",
    "        return: bs4.BeautifulSoup\n",
    "        '''\n",
    "        mybytes = urllib.request.urlopen(url).read().decode(\"utf8\")\n",
    "        return BeautifulSoup(mybytes, features=\"lxml\")\n",
    "\n",
    "    def get_download_urls(parsed_html):\n",
    "        '''\n",
    "        param parsed_html: bs4.BeautifulSoup object\n",
    "        return: list of url strings that download csvs, list of url \n",
    "        strings that download xlsx\n",
    "        '''\n",
    "        table_data = parsed_html.body.find('table', attrs={'class':'usa-table usa-table--striped usa-table--stacked-header usa-table--borderless'})\n",
    "        download_url = r\"https://www.ers.usda.gov\"\n",
    "        urls = [download_url + i['href'] for i in table_data.find_all(\"a\")]\n",
    "        return [x for x in urls if \"csv\" in x], [x for x in urls if \"xlsx\" in x]\n",
    "\n",
    "    def print_total(xls, csv):\n",
    "        '''\n",
    "        param xls: length of list of url that download xlsx\n",
    "        param csv: length of list of url that download csv\n",
    "        '''\n",
    "        print(\"There is a total number of\",xls+csv, \"files,\",xls,\"excel files and\",csv, \"csv files\")\n",
    "\n",
    "    parsed_html = get_parsed_html(url)\n",
    "    \n",
    "    csv, xls = get_download_urls(parsed_html)\n",
    "    \n",
    "    print_total(len(xls), len(csv))\n",
    "    \n",
    "    return xls, csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ce2188-8ae8-404c-b227-dd18705305f1",
   "metadata": {},
   "source": [
    "## Calling our function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "721aa5e4-b056-4b2c-b17b-ac36293db92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a total number of 11 files, 11 excel files and 0 csv files\n"
     ]
    }
   ],
   "source": [
    "xls, csv = downloadables(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb4b43f-23c9-4ce9-8235-e7cafa9ef74e",
   "metadata": {},
   "source": [
    "## Creating a list with all \".xlsx\" and \".csv\" files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76bec892-e0c6-4fad-953d-04896765bbe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.ers.usda.gov/webdocs/DataFiles/104360/MeatStatsRecent.xlsx?v=6500',\n",
       " 'https://www.ers.usda.gov/webdocs/DataFiles/104360/MeatStatsFull.xlsx?v=6500',\n",
       " 'https://www.ers.usda.gov/webdocs/DataFiles/104360/MeatSDRecent.xlsx?v=6500',\n",
       " 'https://www.ers.usda.gov/webdocs/DataFiles/104360/MeatSDFull.xlsx?v=6500',\n",
       " 'https://www.ers.usda.gov/webdocs/DataFiles/104360/BTECOST.xlsx?v=6500',\n",
       " 'https://www.ers.usda.gov/webdocs/DataFiles/104360/ProductionIndicators.xlsx?v=6500',\n",
       " 'https://www.ers.usda.gov/webdocs/DataFiles/104360/LivestockPrices.xlsx?v=6500',\n",
       " 'https://www.ers.usda.gov/webdocs/DataFiles/104360/WholesalePrices.xlsx?v=6500',\n",
       " 'https://www.ers.usda.gov/webdocs/DataFiles/104360/highplainscattlefeedingsimulator.xlsx?v=6500',\n",
       " 'https://www.ers.usda.gov/webdocs/DataFiles/104360/heifersenteringherd.xlsx?v=6500',\n",
       " 'https://www.ers.usda.gov/webdocs/DataFiles/104360/FeederCattleSuppliesOutsideFeedlots.xlsx?v=6500']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_urls = xls + csv\n",
    "list_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f0e53a-dbef-4f03-b36f-c75c55ea49a2",
   "metadata": {},
   "source": [
    "## Using regular expressions to get the files' names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d3a1f84-fa98-464c-a36b-159d2c390e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_names = [x.split(\"/\")[-1].split(\"?\")[0] for x in list_urls]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee036e1-e020-4cfc-b53c-0fb88012f0e9",
   "metadata": {},
   "source": [
    "## Finally, we create a tuple with the file name and the url to get the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f54e3d3e-6777-4eaf-aff3-7f9504a37846",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_list = list(zip(list_urls, list_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71e0d4ad-c1f9-4b57-8886-52687822564f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://www.ers.usda.gov/webdocs/DataFiles/104360/MeatStatsRecent.xlsx?v=952.7',\n",
       "  'MeatStatsRecent.xlsx'),\n",
       " ('https://www.ers.usda.gov/webdocs/DataFiles/104360/MeatStatsFull.xlsx?v=952.7',\n",
       "  'MeatStatsFull.xlsx'),\n",
       " ('https://www.ers.usda.gov/webdocs/DataFiles/104360/MeatSDRecent.xlsx?v=952.7',\n",
       "  'MeatSDRecent.xlsx'),\n",
       " ('https://www.ers.usda.gov/webdocs/DataFiles/104360/MeatSDFull.xlsx?v=952.7',\n",
       "  'MeatSDFull.xlsx'),\n",
       " ('https://www.ers.usda.gov/webdocs/DataFiles/104360/BTECOST.xlsx?v=952.7',\n",
       "  'BTECOST.xlsx'),\n",
       " ('https://www.ers.usda.gov/webdocs/DataFiles/104360/ProductionIndicators.xlsx?v=952.7',\n",
       "  'ProductionIndicators.xlsx'),\n",
       " ('https://www.ers.usda.gov/webdocs/DataFiles/104360/LivestockPrices.xlsx?v=952.7',\n",
       "  'LivestockPrices.xlsx'),\n",
       " ('https://www.ers.usda.gov/webdocs/DataFiles/104360/WholesalePrices.xlsx?v=952.7',\n",
       "  'WholesalePrices.xlsx'),\n",
       " ('https://www.ers.usda.gov/webdocs/DataFiles/104360/highplainscattlefeedingsimulator.xlsx?v=952.7',\n",
       "  'highplainscattlefeedingsimulator.xlsx'),\n",
       " ('https://www.ers.usda.gov/webdocs/DataFiles/104360/heifersenteringherd.xlsx?v=952.7',\n",
       "  'heifersenteringherd.xlsx'),\n",
       " ('https://www.ers.usda.gov/webdocs/DataFiles/104360/FeederCattleSuppliesOutsideFeedlots.xlsx?v=952.7',\n",
       "  'FeederCattleSuppliesOutsideFeedlots.xlsx')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ee67a1-4b06-41f1-be0d-278673dc783e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
